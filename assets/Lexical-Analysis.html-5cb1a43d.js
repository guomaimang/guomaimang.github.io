const e=JSON.parse('{"key":"v-0fa834a1","path":"/note/cs/os/compiler-design/Lexical-Analysis.html","title":"Lexical Analysis","lang":"zh-CN","frontmatter":{"article":false,"date":"2022-11-09T00:00:00.000Z","order":2,"headerDepth":2,"description":"Lexical Analysis 1667899031764.png Introduction Why we need lexical analysis? Its input and output. How to specify「指定」 tokens: Regular Expression Regular Expression -&gt; Lex (software tool) Regular Expression -&gt; Finite Automata","head":[["meta",{"property":"og:url","content":"https://guomaimang.github.io/note/cs/os/compiler-design/Lexical-Analysis.html"}],["meta",{"property":"og:site_name","content":"HAN Jiaming"}],["meta",{"property":"og:title","content":"Lexical Analysis"}],["meta",{"property":"og:description","content":"Lexical Analysis 1667899031764.png Introduction Why we need lexical analysis? Its input and output. How to specify「指定」 tokens: Regular Expression Regular Expression -&gt; Lex (software tool) Regular Expression -&gt; Finite Automata"}],["meta",{"property":"og:type","content":"website"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-09-15T05:33:29.000Z"}],["meta",{"property":"article:author","content":"Hirsun (HAN Jiaming)"}],["meta",{"property":"article:published_time","content":"2022-11-09T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-09-15T05:33:29.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"WebPage\\",\\"name\\":\\"Lexical Analysis\\",\\"description\\":\\"Lexical Analysis 1667899031764.png Introduction Why we need lexical analysis? Its input and output. How to specify「指定」 tokens: Regular Expression Regular Expression -&gt; Lex (software tool) Regular Expression -&gt; Finite Automata\\"}"]]},"headers":[{"level":2,"title":"Introduction","slug":"introduction","link":"#introduction","children":[]},{"level":2,"title":"为何需要词法分析","slug":"为何需要词法分析","link":"#为何需要词法分析","children":[]},{"level":2,"title":"What is a token","slug":"what-is-a-token","link":"#what-is-a-token","children":[]},{"level":2,"title":"What are tokens for","slug":"what-are-tokens-for","link":"#what-are-tokens-for","children":[]},{"level":2,"title":"How to recognize","slug":"how-to-recognize","link":"#how-to-recognize","children":[]},{"level":2,"title":"Specifying tokens","slug":"specifying-tokens","link":"#specifying-tokens","children":[]},{"level":2,"title":"Implementation","slug":"implementation","link":"#implementation","children":[]}],"git":{"createdTime":1726378409000,"updatedTime":1726378409000,"contributors":[{"name":"hanjiaming","email":"47519540+guomaimang@users.noreply.github.com","commits":1}]},"readingTime":{"minutes":6.24,"words":624},"filePathRelative":"note/cs/os/compiler-design/Lexical-Analysis.md","localizedDate":"2022年11月9日","excerpt":"<h1> Lexical Analysis</h1>\\n<figure><img src=\\"https://pic.hanjiaming.com.cn/2022/11/08/a93b990def1ef.png\\" alt=\\"1667899031764.png\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>1667899031764.png</figcaption></figure>\\n<h2> Introduction</h2>\\n<ul>\\n<li>Why we need lexical analysis? Its input and output.</li>\\n<li>How to specify「指定」 tokens: Regular Expression\\n<ul>\\n<li>Regular Expression -&gt; Lex (software tool)</li>\\n<li>Regular Expression -&gt; Finite Automata</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{e as data};
