const e=JSON.parse('{"key":"v-456bb4e2","path":"/note/ds/ml/basic-models/linear-regression.html","title":"线性回归模型","lang":"zh-CN","frontmatter":{"article":false,"date":"2022-07-18T00:00:00.000Z","order":3,"author":"Hirsun, Belter","headerDepth":2,"description":"线性回归模型 线性回归应该是我们听过次数最多的机器学习算法了。在一般的统计学教科书中，最后都会提到这种方法。因此该算法也算是架起了数理统计与机器学习之间的桥梁。 线性回归虽然常见，但是却并不简单。该算法中几乎包含了所有有监督机器学习算法的重要知识点，比如数据的表示、参数的训练、模型的评价、利用正则化防止过拟合等概念。 线性回归模型最小化点与超平面（单个特征的线）之间的距离。 所以说如果掌握了线性回归，可以为后面的学习打下坚实的基础。 基本形式 最简单的线性回归就是直接利用一条直线拟合二维平面上的一系列点，目的是利用这条直线概括所有训练集中样本的散布规律或趋势，最终用于新样本点的预测。","head":[["meta",{"property":"og:url","content":"https://guomaimang.github.io/note/ds/ml/basic-models/linear-regression.html"}],["meta",{"property":"og:site_name","content":"HAN Jiaming"}],["meta",{"property":"og:title","content":"线性回归模型"}],["meta",{"property":"og:description","content":"线性回归模型 线性回归应该是我们听过次数最多的机器学习算法了。在一般的统计学教科书中，最后都会提到这种方法。因此该算法也算是架起了数理统计与机器学习之间的桥梁。 线性回归虽然常见，但是却并不简单。该算法中几乎包含了所有有监督机器学习算法的重要知识点，比如数据的表示、参数的训练、模型的评价、利用正则化防止过拟合等概念。 线性回归模型最小化点与超平面（单个特征的线）之间的距离。 所以说如果掌握了线性回归，可以为后面的学习打下坚实的基础。 基本形式 最简单的线性回归就是直接利用一条直线拟合二维平面上的一系列点，目的是利用这条直线概括所有训练集中样本的散布规律或趋势，最终用于新样本点的预测。"}],["meta",{"property":"og:type","content":"website"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-09-15T05:33:29.000Z"}],["meta",{"property":"article:author","content":"Hirsun, Belter"}],["meta",{"property":"article:published_time","content":"2022-07-18T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-09-15T05:33:29.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"WebPage\\",\\"name\\":\\"线性回归模型\\",\\"description\\":\\"线性回归模型 线性回归应该是我们听过次数最多的机器学习算法了。在一般的统计学教科书中，最后都会提到这种方法。因此该算法也算是架起了数理统计与机器学习之间的桥梁。 线性回归虽然常见，但是却并不简单。该算法中几乎包含了所有有监督机器学习算法的重要知识点，比如数据的表示、参数的训练、模型的评价、利用正则化防止过拟合等概念。 线性回归模型最小化点与超平面（单个特征的线）之间的距离。 所以说如果掌握了线性回归，可以为后面的学习打下坚实的基础。 基本形式 最简单的线性回归就是直接利用一条直线拟合二维平面上的一系列点，目的是利用这条直线概括所有训练集中样本的散布规律或趋势，最终用于新样本点的预测。\\"}"]]},"headers":[{"level":2,"title":"基本形式","slug":"基本形式","link":"#基本形式","children":[]},{"level":2,"title":"代价函数","slug":"代价函数","link":"#代价函数","children":[]},{"level":2,"title":"利用正规方程求解","slug":"利用正规方程求解","link":"#利用正规方程求解","children":[]},{"level":2,"title":"利用梯度下降训练模型","slug":"利用梯度下降训练模型","link":"#利用梯度下降训练模型","children":[{"level":3,"title":"梯度下降的一般步骤","slug":"梯度下降的一般步骤","link":"#梯度下降的一般步骤","children":[]},{"level":3,"title":"学习率","slug":"学习率","link":"#学习率","children":[]},{"level":3,"title":"代价函数的梯度","slug":"代价函数的梯度","link":"#代价函数的梯度","children":[]},{"level":3,"title":"具体的过程","slug":"具体的过程","link":"#具体的过程","children":[]}]},{"level":2,"title":"使用scikit-learn工具包","slug":"使用scikit-learn工具包","link":"#使用scikit-learn工具包","children":[]},{"level":2,"title":"Reference","slug":"reference","link":"#reference","children":[]}],"git":{"createdTime":1726378409000,"updatedTime":1726378409000,"contributors":[{"name":"hanjiaming","email":"47519540+guomaimang@users.noreply.github.com","commits":1}]},"readingTime":{"minutes":25.64,"words":2564},"filePathRelative":"note/ds/ml/basic-models/linear-regression.md","localizedDate":"2022年7月18日","excerpt":"<h1> 线性回归模型</h1>\\n<p>线性回归应该是我们听过次数最多的机器学习算法了。在一般的统计学教科书中，最后都会提到这种方法。因此该算法也算是架起了数理统计与机器学习之间的桥梁。</p>\\n<p>线性回归虽然常见，但是却并不简单。该算法中几乎包含了所有有监督机器学习算法的重要知识点，比如数据的表示、参数的训练、模型的评价、利用正则化防止过拟合等概念。</p>\\n<p><strong>线性回归模型最小化点与超平面（单个特征的线）之间的距离。</strong> 所以说如果掌握了线性回归，可以为后面的学习打下坚实的基础。</p>\\n<h2> 基本形式</h2>\\n<p>最简单的线性回归就是直接利用一条直线拟合二维平面上的一系列点，目的是利用这条直线概括所有训练集中样本的散布规律或趋势，最终用于新样本点的预测。</p>","autoDesc":true}');export{e as data};
