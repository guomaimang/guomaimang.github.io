const e=JSON.parse('{"key":"v-28656591","path":"/note/ds/ml/basic-models/polynomial-regression.html","title":"多项式回归模型","lang":"zh-CN","frontmatter":{"article":false,"date":"2022-07-18T00:00:00.000Z","order":4,"author":"Hirsun, Belter","headerDepth":2,"description":"多项式回归模型 在上一篇的一般线性回归中，使用的假设函数是一元一次方程，也就是二维平面上的一条直线。但是很多时候可能会遇到直线方程无法很好的拟合数据的情况，这个时候可以尝试使用多项式回归。 多项式回归中，加入了特征的更高次方（例如平方项或立方项），也相当于增加了模型的自由度，用来捕获数据中非线性的变化。 添加高阶项的时候，也增加了模型的复杂度。随着模型复杂度的升高，模型的容量以及拟合数据的能力增加，可以进一步降低训练误差，但导致过拟合的风险也随之增加。下图展示了模型复杂度与训练误差及测试误差之间的关系","head":[["meta",{"property":"og:url","content":"https://guomaimang.github.io/note/ds/ml/basic-models/polynomial-regression.html"}],["meta",{"property":"og:site_name","content":"HAN Jiaming"}],["meta",{"property":"og:title","content":"多项式回归模型"}],["meta",{"property":"og:description","content":"多项式回归模型 在上一篇的一般线性回归中，使用的假设函数是一元一次方程，也就是二维平面上的一条直线。但是很多时候可能会遇到直线方程无法很好的拟合数据的情况，这个时候可以尝试使用多项式回归。 多项式回归中，加入了特征的更高次方（例如平方项或立方项），也相当于增加了模型的自由度，用来捕获数据中非线性的变化。 添加高阶项的时候，也增加了模型的复杂度。随着模型复杂度的升高，模型的容量以及拟合数据的能力增加，可以进一步降低训练误差，但导致过拟合的风险也随之增加。下图展示了模型复杂度与训练误差及测试误差之间的关系"}],["meta",{"property":"og:type","content":"website"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-09-15T05:33:29.000Z"}],["meta",{"property":"article:author","content":"Hirsun, Belter"}],["meta",{"property":"article:published_time","content":"2022-07-18T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-09-15T05:33:29.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"WebPage\\",\\"name\\":\\"多项式回归模型\\",\\"description\\":\\"多项式回归模型 在上一篇的一般线性回归中，使用的假设函数是一元一次方程，也就是二维平面上的一条直线。但是很多时候可能会遇到直线方程无法很好的拟合数据的情况，这个时候可以尝试使用多项式回归。 多项式回归中，加入了特征的更高次方（例如平方项或立方项），也相当于增加了模型的自由度，用来捕获数据中非线性的变化。 添加高阶项的时候，也增加了模型的复杂度。随着模型复杂度的升高，模型的容量以及拟合数据的能力增加，可以进一步降低训练误差，但导致过拟合的风险也随之增加。下图展示了模型复杂度与训练误差及测试误差之间的关系\\"}"]]},"headers":[{"level":2,"title":"一般形式","slug":"一般形式","link":"#一般形式","children":[]},{"level":2,"title":"代价函数","slug":"代价函数","link":"#代价函数","children":[]}],"git":{"createdTime":1726378409000,"updatedTime":1726378409000,"contributors":[{"name":"hanjiaming","email":"47519540+guomaimang@users.noreply.github.com","commits":1}]},"readingTime":{"minutes":5.81,"words":581},"filePathRelative":"note/ds/ml/basic-models/polynomial-regression.md","localizedDate":"2022年7月18日","excerpt":"<h1> 多项式回归模型</h1>\\n<p>在上一篇的一般线性回归中，使用的假设函数是一元一次方程，也就是二维平面上的一条直线。但是很多时候可能会遇到直线方程无法很好的拟合数据的情况，这个时候可以尝试使用多项式回归。</p>\\n<p>多项式回归中，加入了特征的更高次方（例如平方项或立方项），也相当于增加了模型的自由度，用来捕获数据中非线性的变化。</p>\\n<p>添加高阶项的时候，也增加了模型的复杂度。随着模型复杂度的升高，模型的容量以及拟合数据的能力增加，可以进一步降低训练误差，但导致过拟合的风险也随之增加。下图展示了模型复杂度与训练误差及测试误差之间的关系</p>\\n<img src=\\"https://pic.hanjiaming.com.cn/2022/07/11/e0be05b7c05ff.png\\" alt=\\"1657509413958.png\\" style=\\"zoom:50%;\\">","autoDesc":true}');export{e as data};
